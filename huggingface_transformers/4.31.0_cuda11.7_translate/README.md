# Huggingface transformers (falcontune)

Docker image for [Huggingface transformers](https://github.com/huggingface/transformers) 4.31.0
that contains support for building translation models.

Uses PyTorch 2.0.1, CUDA 11.7

## Quick start

### Inhouse registry

* Log into registry using *public* credentials:

  ```bash
  docker login -u public -p public public.aml-repo.cms.waikato.ac.nz:443 
  ```

* Create the `cache` directory (to house downloaded dataset and models):

  ```bash
  mkdir cache triton
  ```

* Launch docker container

  ```bash
  docker run \
    -u $(id -u):$(id -g) -e USER=$USER \
    --gpus=all \
    --shm-size 8G \
    --net=host \
    -v `pwd`:/workspace \
    -v `pwd`/cache:/.cache \
    -v `pwd`/triton:/.triton \
    -it public.aml-repo.cms.waikato.ac.nz:443/pytorch/pytorch-huggingface-transformers:4.31.0_cuda11.7_translate
  ```

### Docker hub
  
* Create the `cache` directory (to house downloaded dataset and models):

  ```bash
  mkdir cache triton
  ```

* Launch docker container

  ```bash
  docker run \
    -u $(id -u):$(id -g) -e USER=$USER \
    --gpus=all \
    --shm-size 8G \
    --net=host \
    -v `pwd`:/workspace \
    -v `pwd`/cache:/.cache \
    -v `pwd`/triton:/.triton \
    -it waikatodatamining/pytorch-huggingface-transformers:4.31.0_cuda11.7_translate
  ```

### Build local image

* Build the image from Docker file (from within /path_to/huggingface-transformers/4.31.0_cuda11.7_translate)

  ```bash
  docker build -t huggingface-transformers .
  ```
  
* Run the container

  ```bash
  docker run --gpus=all --shm-size --net=host 8G -v /local/dir:/container/dir -it huggingface-transformers
  ```
  `/local/dir:/container/dir` maps a local disk directory into a directory inside the container


## Publish images

### Build

```bash
docker build -t pytorch-huggingface-transformers:4.31.0_cuda11.7_translate .
```

### Inhouse registry  
  
* Tag

  ```bash
  docker tag \
    pytorch-huggingface-transformers:4.31.0_cuda11.7_translate \
    public-push.aml-repo.cms.waikato.ac.nz:443/pytorch/pytorch-huggingface-transformers:4.31.0_cuda11.7_translate
  ```
  
* Push

  ```bash
  docker push public-push.aml-repo.cms.waikato.ac.nz:443/pytorch/pytorch-huggingface-transformers:4.31.0_cuda11.7_translate
  ```
  If error "no basic auth credentials" occurs, then run (enter username/password when prompted):
  
  ```bash
  docker login public-push.aml-repo.cms.waikato.ac.nz:443
  ```

### Docker hub  
  
* Tag

  ```bash
  docker tag \
    pytorch-huggingface-transformers:4.31.0_cuda11.7_translate \
    waikatodatamining/pytorch-huggingface-transformers:4.31.0_cuda11.7_translate
  ```
  
* Push

  ```bash
  docker push waikatodatamining/pytorch-huggingface-transformers:4.31.0_cuda11.7_translate
  ```
  If error "no basic auth credentials" occurs, then run (enter username/password when prompted):
  
  ```bash
  docker login
  ```


## Permissions

When running the docker container as regular use, you will want to set the correct
user and group on the files generated by the container (aka the user:group launching
the container):

```bash
docker run -u $(id -u):$(id -g) -e USER=$USER ...
```

## Scripts

* `translation_train` - performs a training run (calls `/opt/translate/run_translation.py`)
* `translation_predict_poll` - file polling for making predictions on JSON prompts
* `translation_predict_redis` - makes predictions for JSON prompts via Redis

### Prompt format

```json
{
  "prompt": "the prompt text."
}
```


## Usage

### Launch image

```bash
docker run \
  -u $(id -u):$(id -g) -e USER=$USER \
  --gpus=all \
  --shm-size 8G \
  --net=host \
  -v `pwd`:/workspace \
  -v `pwd`/cache:/.cache \
  -v `pwd`/triton:/.triton \
  -it pytorch-huggingface-transformers:4.31.0_cuda11.7_translate
```

### Train

* Have the data in [jsonlines](https://jsonlines.org/) format and make sure to use `.json` as extension,
  not `.jsonl` or `.jsonlines`:

  ```json
  { "translation": { "en": "Others have dismissed him as a joke.", "ro": "Alții l-au numit o glumă." } }
  ```

* Store the data in the current directory from which you started the docker container in the `data`
  sub directory.

* Create the directory `output` on the same level as `data`.

* Assuming that you are translating from English to French, you can start the 
  training with a command like this (uses train and validation set):

```bash
train_translation \
  --model_name_or_path t5-small \
  --tokenizer_name t5-small \
  --cache_dir /.cache \
  --source_lang en \
  --target_lang mi \
  --source_prefix 'translate English to French: ' \
  --train_file /workspace/data/train.json \
  --validation_file /workspace/data/val.json \
  --overwrite_cache \
  --output_dir /workspace/output \
  --overwrite_output_dir \
  --do_train \
  --do_eval \
  --evaluation_strategy="steps" \
  --num_train_epochs 10 \
  --fp16 \
  --eval_steps 150 \
  --use_fast_tokenizer \
  --logging_dir /workspace/output/runs \
  --gradient_accumulation_steps 8 \
  --per_device_train_batch_size 4 \
  --learning_rate 5e-06 \
  --warmup_steps 10 \
  --save_strategy="epoch"
```

